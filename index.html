<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="UniFuture">
  <meta name="keywords" content="Driving World Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UniFuture</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">



  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>


</head>
<body>


<script src="./static/js/vanilla-back-to-top.min.js"></script>
      <script>addBackToTop({
          backgroundColor: '#fff',
          innerHTML: 'Back to Top',
          textColor: '#333'
        })
      </script>
      <style>
          #back-to-top {
            border: 1px solid #ccc;
            border-radius: 0;
            font-size: 15px;
            width: 100px;
            text-align: center;
            line-height: 30px;
            height: 30px;
          }
      </style>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">Seeing the Future, Perceiving the Future: A Unified Driving World Model for Future Generation and Perception</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://dk-liang.github.io/" target="_blank" rel="noopener noreferrer">Dingkang Liang</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=H_nRYBQAAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Dingyuan Zhang</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://lmd0311.github.io/" target="_blank" rel="noopener noreferrer">Xin Zhou</a><sup>1</sup>,</span>
            <span class="author-block">
              Sifan Tu</a><sup>1</sup>,</span> 
            <span class="author-block">
              Tianrui Feng</a><sup>1</sup>,</span>
            <span class="author-block">
                Xiaofan Li</a><sup>2</sup>,</span> 
              <span class="author-block">
                Yumeng Zhang</a><sup>2</sup>,</span>
              <span class="author-block">
                Mingyang Du</a><sup>1</sup>,</span>
              <span class="author-block">
                Xiao Tan</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=UeltiQ4AAAAJ&hl=en" target="_blank" rel="noopener noreferrer">Xiang Bai</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Huazhong University of Science & Technology,</span>
            <span class="author-block"><sup>2</sup>Baidu,</span> <br>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup> Equal contribution.</span>
            <!-- <span class="author-block"><sup>â€ </sup> Project leader</span> -->

          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/dk-liang/UniFuture"
                   class="external-link button is-normal is-rounded is-dark" target="_blank" rel="noopener noreferrer">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present UniFuture, a simple yet effective driving world model that seamlessly integrates future scene generation and perception within a single framework. Unlike existing models focusing solely on pixel-level future prediction or geometric reasoning, our approach jointly models future appearance (i.e., RGB image) and geometry (i.e., depth), ensuring coherent predictions. Specifically, during the training, we first introduce a Dual-Latent Sharing (DLS) scheme, which transfers image and depth sequence in a shared latent space, allowing both modalities to benefit from shared feature learning. Additionally, we propose a Multi-scale Latent Interaction (MLI) mechanism, which facilitates bidirectional refinement between image and depth features at multiple spatial scales, effectively enhancing geometry consistency and perceptual alignment. During testing, our UniFuture can easily predict high-consistency future image-depth pairs by only using the current image as input. Extensive experiments on the nuScenes dataset demonstrate that UniFuture outperforms specialized models on future generation and perception tasks, highlighting the advantages of a unified, structurally-aware world model.         </div>
      
            <div class="item">
              <img src="./static/images/intro.png" alt="MY ALT TEXT"/>    
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Pipeline</h2>
      <div class="item">
        <img src="static/images/pipeline.png" alt="MY ALT TEXT"/>
       </h2>
     </div>
    </div>
  </div>
</div>
</div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">

      <div class="item"></div>
      <h3 class="title is-4">Demo</h3>
      <div class="content has-text-justified">
        <div class="column is-center has-text-centered">

        <img src="static/images/visualization.png" alt="MY ALT TEXT"/>
        <p>Visualization</p>
        </img>

        <video id="compare-video1" autoplay loop controls="" preload="auto" playsinline="" width="100%">
          <source src="./static/images/demo1.mp4" type="video/mp4">
        </video>
        <p>Example 1</p>
        <video id="compare-video2" autoplay loop controls="" preload="auto" playsinline="" width="100%">
          <source src="./static/images/demo2.mp4" type="video/mp4">
        </video>        
        <p>Example 2</p>
        <video id="compare-video3" autoplay loop controls="" preload="auto" playsinline="" width="100%">
          <source src="./static/images/demo3.mp4" type="video/mp4">
        </video>
        <p>Example 3</p>
        <video id="compare-video4" autoplay loop controls="" preload="auto" playsinline="" width="100%">
          <source src="./static/images/demo4.mp4" type="video/mp4">
        </video>
      <p>Example 4</p>

    </div>
  </div>
</div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Main Results</h2>
        <div class="item">
        <div class="content has-text-justified">
        </div>
        <div class="column is-center has-text-centered">
            <img src="./static/images/main_results.png"
                 class="interpolation-image"
                 />
        </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{liang2025unifuture,
        title={Seeing the Future, Perceiving the Future: A Unified Driving World Model for Future Generation and Perception},
        author={Liang, Dingkang and Zhang, Dingyuan and Zhou, Xin and Tu, Sifan and Feng, Tianrui and Li, Xiaofan and Zhang, Yumeng and Du, Mingyang and Tan, Xiao and Bai, Xiang},

        year={2025}
      }
    </code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <small><p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p></small>
          <small><p>
            We sincerely appreciate Nerfies authors <a href="https://github.com/nerfies/nerfies.github.io"> for their awesome templates.
          </p></small>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>


</html>